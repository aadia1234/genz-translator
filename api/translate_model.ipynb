{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Aadi Anand\\OneDrive\\Desktop\\genz-translator\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer,AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you do not meet a man but frowns:</td>\n",
       "      <td>every man you meet these days is frowning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our bloods  no more obey the heavens than our...</td>\n",
       "      <td>our bodies are in agreement with the planetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but what's the matter?</td>\n",
       "      <td>what's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>his daughter, and the heir of's kingdom, whom...</td>\n",
       "      <td>the king wanted his daughter, the only heir to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>she's wedded;  her husband banish'd; she impr...</td>\n",
       "      <td>she's married, her husband is banished, she's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51782</th>\n",
       "      <td>he hath not told us of the captain yet.</td>\n",
       "      <td>he hasn't told us about that captain yet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51783</th>\n",
       "      <td>when that is known and golden time convents, ...</td>\n",
       "      <td>when that's taken care of and the time is conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>meantime, sweet sister,  we will not part fro...</td>\n",
       "      <td>until then, sweet sister-in-law, we won't leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51785</th>\n",
       "      <td>cesario, come,  for so you shall be, while yo...</td>\n",
       "      <td>cesario, come here. you'll be cesario to me wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51786</th>\n",
       "      <td>when that i was and a little tiny boy,    with...</td>\n",
       "      <td>when i was just a tiny little boy,with hey, ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51787 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      og  \\\n",
       "0                     you do not meet a man but frowns:    \n",
       "1       our bloods  no more obey the heavens than our...   \n",
       "2                               but what's the matter?     \n",
       "3       his daughter, and the heir of's kingdom, whom...   \n",
       "4       she's wedded;  her husband banish'd; she impr...   \n",
       "...                                                  ...   \n",
       "51782           he hath not told us of the captain yet.    \n",
       "51783   when that is known and golden time convents, ...   \n",
       "51784   meantime, sweet sister,  we will not part fro...   \n",
       "51785   cesario, come,  for so you shall be, while yo...   \n",
       "51786  when that i was and a little tiny boy,    with...   \n",
       "\n",
       "                                                       t  \n",
       "0             every man you meet these days is frowning.  \n",
       "1       our bodies are in agreement with the planetar...  \n",
       "2                                          what's wrong?  \n",
       "3      the king wanted his daughter, the only heir to...  \n",
       "4       she's married, her husband is banished, she's...  \n",
       "...                                                  ...  \n",
       "51782         he hasn't told us about that captain yet.   \n",
       "51783  when that's taken care of and the time is conv...  \n",
       "51784  until then, sweet sister-in-law, we won't leav...  \n",
       "51785  cesario, come here. you'll be cesario to me wh...  \n",
       "51786  when i was just a tiny little boy,with hey, ho...  \n",
       "\n",
       "[51787 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"shakespeare.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0', 'id'])\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].str.lower()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# This will fallback on the CPU if no CUDA-enabled GPU is available.\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "# model = MyModel()\n",
    "# model.to(device)\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     batch = batch.to(device)\n",
    "#     prediction = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 41429/41429 [00:02<00:00, 18059.72 examples/s]\n",
      "Map: 100%|██████████| 10358/10358 [00:00<00:00, 21944.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Initialize tokenizer and model\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "# Initialize tokenizer and model - explicitly put on CUDA\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# THE KEY FIX: T5 models need a task prefix\n",
    "def preprocess_function(examples):\n",
    "    # Add prefix for T5 tasks\n",
    "    prefix = \"translate Shakespearean English to Modern English: \"\n",
    "    inputs = [prefix + text for text in examples[\"og\"]]\n",
    "    targets = [text for text in examples[\"t\"]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "# Convert your data into a dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Split the dataset \n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "tokenized_data = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(pred, labels):\n",
    "    preds = [pred.strip() for pred in pred]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    \n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5180' max='5180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5180/5180 10:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.188200</td>\n",
       "      <td>2.003123</td>\n",
       "      <td>13.931000</td>\n",
       "      <td>16.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.151200</td>\n",
       "      <td>1.980601</td>\n",
       "      <td>14.113200</td>\n",
       "      <td>16.826200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5180, training_loss=2.213861543515474, metrics={'train_runtime': 647.6992, 'train_samples_per_second': 127.927, 'train_steps_per_second': 7.998, 'total_flos': 1478116452335616.0, 'train_loss': 2.213861543515474, 'epoch': 2.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results/final_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, #change to bf16=True for XPU\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example translations:\n",
      "----------------------------------------\n",
      "Input:  To be, or not to be, that is the question\n",
      "Output: whether you want to be the other person or not?\n",
      "----------------------------------------\n",
      "Input:  Why have you come to Mr. Smith with this crap?\n",
      "Output: why were you coming to Mr. Smith with this crap?\n",
      "----------------------------------------\n",
      "Input:  our bloods No more obey the heavens than our courtiers Still seem as does the king\n",
      "Output: our bloods can't obey the heavens more than our courtiers; but our bloods seem as if it was the king\n",
      "----------------------------------------\n",
      "Input:  I do not think So fair an outward and such stuff within Endows a man but he.\n",
      "Output: i don't think what I'm gonna say. If an outsider is allowed a man in this country, this is the kind of thing that can only be learned.\n",
      "----------------------------------------\n",
      "Input:  The man who lost the princess is so bad it's impossible to describe him accurately.\n",
      "Output: the man who lost the princess is so bad that it's impossible to tell him accurately.\n",
      "----------------------------------------\n",
      "Input:  Love looks not with the eyes, but with the mind; And therefore is wing'd Cupid painted blind. Nor hath love's mind of any judgment taste; Wings and no eyes figure unheedy haste: And therefore is love said to be a child, Because in choice he is so oft beguil'd.\n",
      "Output: love is not seen by the eyes, but with the mind. and is also drawn by winged Cupid, painted blind. and not love's mind despite any judgment,\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "# model_path = \"./results/final_model\"\n",
    "# model.save_pretrained(model_path)\n",
    "# tokenizer.save_pretrained(model_path)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_path = \"aadia1234/shakespeare-to-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "# Improved translation function with T5 prefix\n",
    "def translate_sentence(sentence):\n",
    "    # Add the required prefix - THIS IS CRUCIAL\n",
    "    prefix = \"translate Shakespearean English to Modern English: \"\n",
    "    input_text = prefix + sentence\n",
    "    \n",
    "    # Prepare the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    device = model.device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate translation with better parameters\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
    "\n",
    "    \n",
    "    # Decode the output\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "# Test with some example sentences\n",
    "test_sentences = [\n",
    "    \"To be, or not to be, that is the question\",\n",
    "    \"Why have you come to Mr. Smith with this crap?\",\n",
    "    \"our bloods No more obey the heavens than our courtiers Still seem as does the king\",\n",
    "    \"I do not think So fair an outward and such stuff within Endows a man but he.\",\n",
    "    \"The man who lost the princess is so bad it's impossible to describe him accurately.\",\n",
    "    \"Love looks not with the eyes, but with the mind; And therefore is wing'd Cupid painted blind. Nor hath love's mind of any judgment taste; Wings and no eyes figure unheedy haste: And therefore is love said to be a child, Because in choice he is so oft beguil'd.\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Translate and display results\n",
    "print(\"Example translations:\")\n",
    "print(\"-\" * 40)\n",
    "for sentence in test_sentences:\n",
    "    translation = translate_sentence(sentence)\n",
    "    print(f\"Input:  {sentence}\")\n",
    "    print(f\"Output: {translation}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"you're a villain, and i'm a villain.\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"aadia1234/shakespeare-to-english\"\n",
    "\n",
    "pipe = pipeline(task=\"translation\", model=model_name)\n",
    "pipe(\"translate Shakespearean English to Modern English: Thou art a villain, and I am a villain too.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
